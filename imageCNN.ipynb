{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=False, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(), #(0,1)\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,16,5,1,2) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(16,32,5,1,2) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(32*7*7,10)\n",
    "        #self.fc2 = nn.Linear(500,10)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.0684, -0.1642, -0.0700,  0.0043,  0.1737],\n",
      "          [-0.1744, -0.0160, -0.1015, -0.1403, -0.1834],\n",
      "          [ 0.1236,  0.1964,  0.0375,  0.0235,  0.0386],\n",
      "          [-0.1053, -0.1916, -0.1605, -0.1984, -0.1818],\n",
      "          [-0.0016,  0.0487,  0.0192,  0.1956, -0.1426]]],\n",
      "\n",
      "\n",
      "        [[[-0.0845, -0.1468, -0.0873,  0.0452,  0.0057],\n",
      "          [-0.1679,  0.1916,  0.0763,  0.0342, -0.0944],\n",
      "          [-0.0533, -0.1918,  0.1823,  0.0154, -0.0661],\n",
      "          [-0.1699,  0.1125,  0.1694, -0.0302,  0.0068],\n",
      "          [-0.0743,  0.1297, -0.0584,  0.1711, -0.1236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1470, -0.0086, -0.1463,  0.1658,  0.1037],\n",
      "          [ 0.0434, -0.1511,  0.0050,  0.0580, -0.1216],\n",
      "          [-0.1829, -0.1616, -0.1467,  0.1850,  0.0640],\n",
      "          [-0.0552, -0.1475, -0.1072, -0.0674,  0.1750],\n",
      "          [ 0.0113,  0.1916,  0.1972,  0.1973, -0.1736]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376, -0.0238, -0.0141, -0.1811, -0.1811],\n",
      "          [ 0.0206, -0.0119,  0.0295,  0.0870, -0.1111],\n",
      "          [-0.0781,  0.0795, -0.0063, -0.1407, -0.1895],\n",
      "          [-0.1732,  0.1579, -0.0718, -0.1024,  0.1909],\n",
      "          [ 0.1230, -0.1434,  0.1320,  0.0016,  0.1100]]],\n",
      "\n",
      "\n",
      "        [[[-0.1003,  0.1469, -0.0280, -0.0021, -0.1904],\n",
      "          [-0.1211,  0.1818, -0.0206, -0.1019, -0.0321],\n",
      "          [ 0.0458, -0.1334, -0.1508,  0.1013, -0.0199],\n",
      "          [ 0.1120,  0.0322, -0.1468,  0.0381,  0.0121],\n",
      "          [-0.0770,  0.1299, -0.1634,  0.1771,  0.0419]]],\n",
      "\n",
      "\n",
      "        [[[-0.1749, -0.1835, -0.1786,  0.1148,  0.1522],\n",
      "          [ 0.1156,  0.0650, -0.0426,  0.1686,  0.0257],\n",
      "          [ 0.0926, -0.1601,  0.1069,  0.0137, -0.1710],\n",
      "          [-0.0241, -0.0883,  0.1716,  0.1236, -0.0412],\n",
      "          [ 0.1904, -0.0593,  0.0599, -0.1181, -0.0331]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0637,  0.0690, -0.1032,  0.1345,  0.0614],\n",
      "          [ 0.1664,  0.1802, -0.1124,  0.0607, -0.1025],\n",
      "          [ 0.1266,  0.0374,  0.1244,  0.0850,  0.1430],\n",
      "          [-0.0119,  0.0176,  0.0785, -0.0971,  0.0437],\n",
      "          [ 0.1501,  0.1199, -0.1194,  0.0931, -0.0320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0595, -0.0861,  0.0506, -0.0297,  0.0337],\n",
      "          [ 0.0450,  0.0164, -0.1656, -0.0126, -0.0667],\n",
      "          [ 0.1865,  0.1117, -0.0492,  0.1624, -0.0780],\n",
      "          [ 0.0277, -0.1419,  0.1895,  0.0069,  0.0699],\n",
      "          [-0.1851,  0.0115, -0.0398,  0.1044,  0.1060]]],\n",
      "\n",
      "\n",
      "        [[[-0.0782,  0.0582, -0.0591, -0.0674, -0.1380],\n",
      "          [-0.0985, -0.0171,  0.1838,  0.0619,  0.1885],\n",
      "          [ 0.0466,  0.0983, -0.0853,  0.1470, -0.0871],\n",
      "          [ 0.0896,  0.1204,  0.1702, -0.1097,  0.1435],\n",
      "          [-0.0281, -0.1572,  0.0737, -0.0776, -0.1940]]],\n",
      "\n",
      "\n",
      "        [[[-0.1618,  0.0152,  0.1826, -0.1124, -0.1953],\n",
      "          [-0.1606, -0.0511,  0.0542,  0.0545,  0.0952],\n",
      "          [ 0.1587, -0.0350,  0.1235, -0.0201, -0.0831],\n",
      "          [ 0.0468,  0.1712, -0.0162,  0.0235, -0.1000],\n",
      "          [-0.0160,  0.1725, -0.0629, -0.0928,  0.1737]]],\n",
      "\n",
      "\n",
      "        [[[-0.0872,  0.1038, -0.1584,  0.0474, -0.0102],\n",
      "          [ 0.1256,  0.0366, -0.1604, -0.0300, -0.0572],\n",
      "          [ 0.1989,  0.1400, -0.0856,  0.0639,  0.1050],\n",
      "          [ 0.0313, -0.0735,  0.1199, -0.1678,  0.1047],\n",
      "          [ 0.1620,  0.0634,  0.0255, -0.1131, -0.0372]]],\n",
      "\n",
      "\n",
      "        [[[-0.1913,  0.1916,  0.1533, -0.0219, -0.0710],\n",
      "          [ 0.1415,  0.1712, -0.1013,  0.0638,  0.0492],\n",
      "          [ 0.1320,  0.0128, -0.0091, -0.1710, -0.0449],\n",
      "          [ 0.0881, -0.1789,  0.0665,  0.0758, -0.1393],\n",
      "          [ 0.0273, -0.1539,  0.1404,  0.1306, -0.1139]]],\n",
      "\n",
      "\n",
      "        [[[-0.0753,  0.0283,  0.1185,  0.0259,  0.1413],\n",
      "          [-0.1341,  0.1540,  0.1044,  0.1707, -0.1744],\n",
      "          [ 0.1296, -0.0396, -0.1982, -0.1486, -0.0883],\n",
      "          [ 0.1205, -0.1088,  0.1896, -0.0058, -0.1924],\n",
      "          [ 0.1428,  0.0812,  0.0675, -0.0424, -0.1080]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0362,  0.0908, -0.0479,  0.0865,  0.1144],\n",
      "          [ 0.1543, -0.0051, -0.1238, -0.0733, -0.1901],\n",
      "          [ 0.0204, -0.0033, -0.1654, -0.1503, -0.1888],\n",
      "          [ 0.0499,  0.0502,  0.0560,  0.1476, -0.1014],\n",
      "          [ 0.1094,  0.1359,  0.0427, -0.0430, -0.1144]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1792,  0.0498,  0.1284, -0.0559, -0.1858],\n",
      "          [-0.1714, -0.0698,  0.1781, -0.0404,  0.1088],\n",
      "          [ 0.1595, -0.1810, -0.1007, -0.0284,  0.1405],\n",
      "          [ 0.1997,  0.0739, -0.1693, -0.1534, -0.1866],\n",
      "          [ 0.1812,  0.0934,  0.1247,  0.0231,  0.1825]]],\n",
      "\n",
      "\n",
      "        [[[-0.1989, -0.0637, -0.1916, -0.1681, -0.0677],\n",
      "          [ 0.0966, -0.1073,  0.0456, -0.1710,  0.0233],\n",
      "          [ 0.0269,  0.0010, -0.1294,  0.0593, -0.1874],\n",
      "          [ 0.1075, -0.1467,  0.1398, -0.1093, -0.0721],\n",
      "          [ 0.0474, -0.1225,  0.0455,  0.0558,  0.0550]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0505,  0.0886,  0.0428,  0.1459, -0.0742, -0.0611,  0.1900, -0.1598,\n",
      "         0.0763,  0.1852, -0.0609, -0.1126,  0.0294,  0.0523, -0.1859, -0.1839],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-8.2211e-03, -9.1214e-03,  3.3817e-02, -4.4425e-02,  4.0188e-02],\n",
      "          [ 4.6947e-03,  1.2737e-02,  4.8515e-03,  1.6124e-02, -1.7257e-02],\n",
      "          [-2.3613e-02,  1.6307e-02, -3.8365e-02,  1.0520e-02, -2.7395e-02],\n",
      "          [ 1.0806e-02, -3.2465e-02, -2.4887e-02, -1.8365e-02,  1.3101e-02],\n",
      "          [-1.6372e-02, -1.6798e-02,  1.9663e-03,  1.8035e-03,  3.6910e-02]],\n",
      "\n",
      "         [[-2.4275e-02, -2.4848e-02, -4.5675e-02,  8.0900e-04, -4.5004e-02],\n",
      "          [-2.8256e-02, -9.3018e-03,  4.4295e-02,  4.3606e-02, -3.9119e-02],\n",
      "          [-1.4035e-02,  6.9204e-03, -4.6076e-02, -4.8800e-02,  4.1430e-02],\n",
      "          [-2.3030e-02,  3.8430e-02,  1.2061e-02, -3.2985e-02, -2.3524e-02],\n",
      "          [ 4.3720e-02,  2.5856e-02, -2.9133e-02, -3.6130e-02, -3.2946e-02]],\n",
      "\n",
      "         [[ 4.5371e-03,  7.8248e-03, -1.1225e-02,  3.8210e-02,  4.1891e-02],\n",
      "          [ 4.1547e-02,  3.6780e-03,  3.7173e-02,  4.2440e-02,  6.8067e-03],\n",
      "          [-3.2355e-03, -3.4305e-02, -3.3381e-02,  1.5074e-02, -3.1091e-02],\n",
      "          [-2.5854e-02, -3.7076e-02, -3.9630e-02, -3.9485e-02, -3.2443e-02],\n",
      "          [ 8.9114e-03,  4.8122e-02, -1.2842e-02,  1.5419e-02,  5.8864e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5550e-02, -3.2302e-02, -2.1314e-03, -1.7802e-02, -4.3586e-02],\n",
      "          [ 6.0265e-03, -3.2659e-02,  3.9900e-02,  4.5512e-02, -1.5788e-02],\n",
      "          [ 3.0398e-02,  2.9767e-02,  4.2308e-03,  4.9528e-02,  3.3836e-02],\n",
      "          [-4.2023e-03, -1.9007e-03, -1.2867e-02, -2.8806e-02,  5.1758e-03],\n",
      "          [ 3.2441e-02, -4.9458e-02, -7.5422e-03,  1.6878e-02,  4.3203e-02]],\n",
      "\n",
      "         [[-6.7786e-03,  1.5078e-02, -1.6954e-02, -1.5988e-02,  5.5609e-03],\n",
      "          [-4.3793e-02,  4.0733e-02, -9.9458e-04,  4.2202e-02,  1.8714e-02],\n",
      "          [ 2.6244e-02,  4.2494e-02, -3.4922e-02,  1.2991e-02,  1.0586e-03],\n",
      "          [ 3.6513e-02,  3.8462e-02,  1.5727e-02, -2.7287e-03,  4.0576e-02],\n",
      "          [ 3.3044e-02, -3.4347e-02, -9.6682e-03,  2.4378e-02,  2.2012e-02]],\n",
      "\n",
      "         [[-2.8364e-02, -3.9771e-02, -4.4502e-02,  3.0344e-02, -4.4994e-02],\n",
      "          [ 3.0125e-02,  3.5744e-02,  3.9411e-02,  3.0646e-02, -4.5634e-02],\n",
      "          [ 7.2991e-03,  9.6333e-03,  4.2576e-02,  1.0802e-02, -1.2215e-02],\n",
      "          [ 3.1741e-02,  3.2553e-02,  2.1800e-02, -2.3540e-02, -3.6822e-02],\n",
      "          [-3.3605e-03,  3.2756e-02, -3.9422e-04, -3.3001e-02, -3.3589e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7631e-02, -4.4473e-02, -2.3699e-02, -1.1322e-02,  4.2414e-02],\n",
      "          [-7.9484e-03,  4.5546e-02,  3.4867e-02,  3.5852e-02, -2.2751e-02],\n",
      "          [ 2.5514e-02, -1.7306e-02, -3.7418e-02,  2.7213e-02,  3.3668e-02],\n",
      "          [ 2.5142e-02, -3.9415e-02, -4.9289e-02,  1.6112e-02,  2.7786e-02],\n",
      "          [-3.3507e-02, -2.3832e-02, -2.8372e-03,  4.2770e-02, -1.7030e-03]],\n",
      "\n",
      "         [[ 1.6458e-02, -1.1659e-02,  2.2419e-02,  2.2052e-03, -1.6191e-02],\n",
      "          [ 2.3981e-02, -4.2293e-02, -8.8753e-03,  1.0411e-02,  2.9796e-02],\n",
      "          [-3.9686e-02, -5.2672e-03, -3.2068e-02,  1.1905e-02,  4.8063e-02],\n",
      "          [ 3.5512e-03,  2.5597e-02,  9.7318e-03, -4.4746e-04,  1.0293e-02],\n",
      "          [-6.9616e-03, -2.7322e-02,  3.2453e-02,  2.4860e-02, -2.0086e-02]],\n",
      "\n",
      "         [[ 4.3689e-02,  1.8286e-02,  1.9786e-02,  3.1617e-02, -3.1456e-02],\n",
      "          [-1.6208e-02,  4.9549e-02,  3.8666e-02, -3.8730e-03,  4.7895e-02],\n",
      "          [-1.6927e-02, -4.1720e-03, -6.7725e-03,  2.8808e-02,  4.1590e-02],\n",
      "          [-1.7030e-02, -2.9222e-02,  1.8063e-02, -4.1216e-02, -4.5579e-02],\n",
      "          [ 2.7589e-02, -3.5144e-02,  3.9783e-02, -2.9033e-02,  4.3104e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3521e-02, -3.5274e-03,  3.0630e-02,  3.3123e-02, -4.6098e-02],\n",
      "          [ 1.2043e-02,  4.3542e-02, -1.8763e-02, -1.7397e-02,  2.8590e-02],\n",
      "          [-1.6684e-02, -3.2575e-02, -1.3570e-02,  1.5963e-02,  3.2209e-03],\n",
      "          [ 1.0990e-02,  4.1101e-02,  1.6954e-02, -1.9985e-02,  2.8583e-02],\n",
      "          [ 1.3657e-02, -4.7490e-02,  3.8757e-02,  2.2427e-02, -5.7800e-03]],\n",
      "\n",
      "         [[ 3.3171e-02, -2.7893e-02, -3.3413e-02,  1.4172e-02, -1.5571e-02],\n",
      "          [ 3.1422e-02, -4.7716e-03,  4.8122e-02,  2.5273e-02,  4.1575e-02],\n",
      "          [-1.9430e-02,  3.7911e-02, -3.6285e-02,  2.5103e-02,  3.0573e-03],\n",
      "          [ 4.1755e-02,  2.9854e-02,  4.4499e-02, -2.5342e-02,  1.6052e-02],\n",
      "          [-1.9156e-02,  2.3591e-02, -2.5838e-02, -1.2161e-02, -4.9339e-03]],\n",
      "\n",
      "         [[-3.9510e-02,  9.1205e-03, -1.1281e-02, -2.2649e-02, -8.1100e-03],\n",
      "          [-5.4816e-03,  2.1183e-02, -3.6564e-02, -1.4306e-02,  3.2341e-02],\n",
      "          [ 4.9931e-02, -2.2469e-02, -4.6190e-02,  1.7374e-02, -4.6434e-03],\n",
      "          [-1.0519e-02,  4.5893e-02, -4.4275e-02,  4.1434e-02, -5.4548e-03],\n",
      "          [ 1.9358e-02, -2.8447e-02, -4.8856e-02, -2.7420e-04, -2.5509e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5822e-02, -4.8377e-02,  2.3747e-02,  1.2439e-02, -1.6279e-02],\n",
      "          [-1.4235e-02,  1.1595e-02, -8.3584e-03, -3.4343e-02,  4.7814e-02],\n",
      "          [ 4.2144e-03,  4.9639e-02,  2.6535e-02, -3.5683e-02, -1.3414e-02],\n",
      "          [ 1.2045e-02,  3.4286e-02, -1.8620e-02,  2.2072e-02, -5.2717e-03],\n",
      "          [ 2.4287e-02,  2.1397e-02,  4.9904e-02, -2.2222e-02, -1.9417e-02]],\n",
      "\n",
      "         [[-3.2402e-02,  7.0277e-03, -1.0083e-02, -4.0759e-02, -4.3715e-02],\n",
      "          [-9.7133e-03, -3.0045e-02,  2.7770e-02, -2.1268e-02,  2.0713e-02],\n",
      "          [-2.7431e-02, -4.0754e-02, -2.5024e-02, -4.6285e-02,  5.5362e-03],\n",
      "          [-2.0902e-03,  4.8948e-03, -1.9986e-02, -2.2268e-02,  3.1192e-02],\n",
      "          [ 2.8863e-02, -2.1545e-02,  8.0090e-03,  1.5348e-02,  7.8082e-03]],\n",
      "\n",
      "         [[-2.9914e-02, -1.7992e-02, -1.1599e-02,  2.9203e-02,  3.1097e-02],\n",
      "          [ 2.6601e-02,  1.0053e-03,  1.1508e-02,  1.8236e-02,  4.9970e-02],\n",
      "          [ 3.5935e-02, -9.0346e-03,  2.2292e-02, -4.1975e-02,  3.1045e-02],\n",
      "          [-1.3868e-02,  4.6084e-02,  2.3107e-02,  2.8189e-03, -2.9293e-02],\n",
      "          [ 2.6809e-02, -1.6602e-02, -4.7927e-02, -1.6052e-02,  2.4291e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1690e-02,  4.9722e-02, -7.7436e-03, -2.3791e-03, -1.3927e-02],\n",
      "          [-1.5547e-02, -1.6334e-02, -3.3169e-02, -2.1996e-02, -3.2108e-02],\n",
      "          [-4.7981e-02, -3.7008e-02, -2.2585e-02, -1.3183e-02, -7.1279e-03],\n",
      "          [ 2.5680e-02,  2.0383e-02,  1.6226e-02, -2.6264e-02,  4.7279e-03],\n",
      "          [-2.3078e-02,  9.5751e-03,  3.6574e-02,  9.5873e-03,  1.9587e-02]],\n",
      "\n",
      "         [[ 3.1824e-02, -1.9546e-02,  2.6290e-02, -3.2855e-02, -4.4098e-03],\n",
      "          [ 3.9924e-02,  3.2681e-02,  2.9430e-02,  3.5876e-02, -1.8291e-02],\n",
      "          [ 2.4376e-02, -4.0519e-02, -8.4134e-03, -4.1230e-02, -3.9576e-03],\n",
      "          [-1.1555e-02, -3.3660e-02, -4.6509e-02,  3.0091e-02, -8.2719e-03],\n",
      "          [ 3.8117e-02, -2.3220e-02,  2.7549e-02, -3.8242e-02, -3.3435e-02]],\n",
      "\n",
      "         [[ 1.7554e-02, -1.7969e-02, -5.3502e-03, -1.5051e-02,  3.2541e-02],\n",
      "          [ 3.9648e-03, -2.2626e-02, -4.6663e-02,  1.7387e-02, -2.8312e-02],\n",
      "          [-1.1936e-02,  1.6533e-02,  2.8399e-03,  4.3375e-02, -7.5897e-04],\n",
      "          [ 2.6173e-02, -2.8062e-02,  1.8449e-02, -4.9801e-02, -4.5621e-02],\n",
      "          [ 3.6037e-02, -3.6343e-02, -1.7866e-02, -4.4821e-02, -1.8451e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7998e-02,  2.7160e-02,  1.5041e-03,  4.1684e-02, -3.2956e-02],\n",
      "          [-1.4047e-02, -3.4822e-02,  2.3339e-02,  4.4598e-02, -8.4070e-03],\n",
      "          [-6.9031e-03, -4.0720e-02,  7.7519e-03,  4.4929e-02,  4.0447e-02],\n",
      "          [ 7.9844e-03,  9.8139e-05,  2.6426e-02,  4.6856e-02,  3.2235e-02],\n",
      "          [-2.6679e-02,  8.8528e-03, -3.2761e-02, -2.7365e-02, -2.1042e-02]],\n",
      "\n",
      "         [[ 4.1186e-02,  3.4559e-02, -2.9076e-02, -3.6220e-02,  1.6615e-02],\n",
      "          [ 2.9785e-02,  2.4745e-02, -2.5443e-02,  2.7050e-02,  9.6187e-03],\n",
      "          [ 2.2162e-02,  3.7381e-02, -2.8026e-02, -4.8700e-02,  4.3491e-02],\n",
      "          [ 4.2709e-02,  3.2838e-02, -3.7563e-02, -2.0107e-02, -4.2077e-02],\n",
      "          [-2.3128e-02,  4.8851e-02, -2.5540e-02, -1.7360e-02,  1.1334e-02]],\n",
      "\n",
      "         [[ 6.6448e-03,  4.2942e-02,  3.8077e-02,  2.3137e-02, -4.8630e-02],\n",
      "          [-4.0975e-03,  1.0746e-02,  3.6029e-02,  2.0296e-02,  4.4568e-02],\n",
      "          [-4.9013e-02,  4.7518e-02,  2.2270e-02, -1.3940e-02, -3.7751e-02],\n",
      "          [ 8.2209e-03,  2.1286e-02, -2.9997e-02, -4.7644e-02, -2.7067e-02],\n",
      "          [-2.6027e-02, -3.0470e-02, -3.1261e-02,  2.0509e-02, -1.2295e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6862e-02,  2.9569e-02, -3.0747e-02,  8.9294e-03,  3.9448e-02],\n",
      "          [ 4.2955e-02, -2.7255e-02,  4.4323e-03,  6.5969e-03, -3.3828e-02],\n",
      "          [ 3.5261e-02,  3.8010e-02, -6.8248e-03,  4.6503e-02, -3.0054e-02],\n",
      "          [ 4.0690e-02, -2.7069e-02,  2.9564e-03, -4.2896e-02,  1.2401e-03],\n",
      "          [-4.3702e-02,  3.4334e-02, -1.4119e-04,  2.3137e-02,  2.6536e-02]],\n",
      "\n",
      "         [[ 4.2683e-02, -4.2607e-02,  7.4883e-03, -1.2682e-02, -3.4246e-02],\n",
      "          [ 2.0183e-02, -1.1169e-02, -2.9145e-02, -4.6093e-03,  1.1694e-02],\n",
      "          [ 2.6268e-02,  1.0082e-02,  3.0992e-02, -1.1826e-02,  3.5545e-03],\n",
      "          [ 1.7014e-02,  3.3798e-02, -2.9544e-02, -3.5566e-02,  1.0734e-02],\n",
      "          [-2.2609e-02,  4.6600e-02,  4.8229e-04, -4.2768e-02,  4.1333e-02]],\n",
      "\n",
      "         [[ 2.9936e-02, -2.8114e-02, -4.5121e-02, -5.3516e-03, -4.0127e-02],\n",
      "          [-4.2202e-04,  1.9444e-02,  3.7838e-02, -3.3203e-03,  3.3528e-02],\n",
      "          [ 1.8781e-02, -4.1233e-02,  2.1410e-02,  1.8386e-02,  6.6076e-03],\n",
      "          [ 5.8633e-03, -2.5957e-02,  1.5962e-02, -3.3692e-02, -2.9817e-02],\n",
      "          [ 3.7079e-02, -1.6663e-04, -2.9403e-02,  3.7619e-02,  4.7471e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3263e-02, -5.0672e-04,  2.5189e-02,  3.0397e-02,  4.1104e-03],\n",
      "          [ 4.2144e-03,  5.4745e-03,  4.6590e-02,  1.4037e-02,  4.3440e-03],\n",
      "          [ 1.4394e-02,  1.3524e-03, -3.2703e-02,  1.7513e-02,  3.9025e-02],\n",
      "          [ 2.6715e-02, -4.0034e-02,  4.3566e-02,  1.4077e-02, -1.7923e-02],\n",
      "          [ 2.5866e-02, -4.9827e-02,  3.8497e-02, -1.2666e-02, -2.9266e-02]],\n",
      "\n",
      "         [[ 2.9525e-02,  6.4029e-03, -4.0748e-02,  1.3044e-02,  3.5282e-02],\n",
      "          [ 3.3714e-02, -1.9836e-02, -3.7747e-02, -8.9575e-03,  2.8706e-04],\n",
      "          [-3.8700e-02, -4.9481e-02,  3.9770e-02, -1.8599e-02,  3.6947e-02],\n",
      "          [ 4.0307e-02,  4.8636e-02, -7.7243e-03, -1.2774e-02,  2.5280e-02],\n",
      "          [ 1.0354e-02, -4.2983e-02, -3.2136e-02, -3.8225e-02,  3.0389e-02]],\n",
      "\n",
      "         [[-2.7586e-02, -2.2380e-02, -8.8906e-04, -3.7215e-02, -1.6403e-02],\n",
      "          [ 7.6639e-03,  3.4187e-02, -1.3986e-03, -3.0326e-02, -2.7619e-02],\n",
      "          [ 1.4041e-02,  3.0946e-02, -3.2280e-02, -2.4958e-02,  1.8988e-02],\n",
      "          [ 3.4194e-02, -2.2613e-03, -2.6232e-02, -1.2471e-02, -4.3889e-02],\n",
      "          [ 4.8121e-02, -1.8947e-02,  2.9880e-02, -4.4345e-02,  1.8521e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6631e-02, -3.9765e-03,  2.8504e-02, -2.2081e-02, -1.9465e-02],\n",
      "          [-1.1907e-02, -1.8593e-02,  2.6369e-02,  4.2351e-02,  3.0553e-02],\n",
      "          [-2.5398e-02, -2.8447e-02, -3.7761e-02, -4.2380e-02,  7.1776e-03],\n",
      "          [-9.5418e-03, -1.3156e-02,  2.8397e-02,  4.0467e-03,  3.0932e-02],\n",
      "          [-1.6858e-02,  3.9420e-02, -1.6632e-04,  3.8404e-02,  4.9761e-02]],\n",
      "\n",
      "         [[-3.5818e-02, -2.2233e-02,  3.8590e-02,  4.0908e-02,  4.7284e-02],\n",
      "          [-2.3678e-02, -3.6835e-02,  3.1005e-02, -2.4248e-02, -4.3160e-02],\n",
      "          [ 3.9009e-02,  1.7145e-02, -2.6768e-02,  3.8509e-02, -4.0747e-02],\n",
      "          [-3.9231e-02, -4.8308e-03, -3.5793e-02, -2.2335e-02, -4.6229e-02],\n",
      "          [-4.8230e-02,  1.5567e-02, -4.9846e-03, -1.0641e-02,  2.7217e-02]],\n",
      "\n",
      "         [[-2.5915e-02,  2.7724e-02,  1.8658e-02, -2.5248e-02,  4.7315e-02],\n",
      "          [-3.3347e-02, -1.5353e-02,  1.0652e-02, -1.1724e-03, -3.4493e-02],\n",
      "          [ 3.5019e-02, -8.9544e-03, -1.7997e-02, -3.0544e-02,  3.2329e-02],\n",
      "          [ 2.0976e-02,  4.1865e-02,  4.8794e-02, -4.1829e-02, -2.5590e-02],\n",
      "          [-3.7861e-03, -2.1211e-02,  1.9080e-02,  1.9488e-02, -8.9055e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1292e-03,  1.1116e-02, -1.6891e-02,  5.1477e-03, -3.9363e-02],\n",
      "          [ 3.0791e-02, -1.7235e-02,  4.2250e-02, -4.0908e-02, -4.1729e-02],\n",
      "          [-3.6486e-02, -1.3896e-02,  3.3878e-04, -3.4051e-02,  1.1484e-02],\n",
      "          [ 2.4618e-02,  1.9406e-02,  3.7843e-02,  1.8062e-03, -1.4346e-02],\n",
      "          [ 3.2444e-02, -4.1221e-02,  4.9280e-02,  1.6202e-02, -1.0029e-02]],\n",
      "\n",
      "         [[-4.0263e-02, -4.1386e-02,  4.3065e-02, -2.5783e-02,  1.8408e-02],\n",
      "          [ 4.7203e-02,  4.7107e-02,  4.8071e-02, -4.1890e-02,  3.6673e-02],\n",
      "          [-2.5282e-02,  2.4743e-02,  1.6887e-02,  3.2353e-02, -2.2693e-02],\n",
      "          [-1.0573e-03,  6.0223e-03,  3.3919e-02, -8.9968e-03,  3.2675e-02],\n",
      "          [-3.4202e-03,  3.7190e-02, -1.0582e-02,  2.0586e-02,  9.4459e-03]],\n",
      "\n",
      "         [[-2.3781e-04,  2.1736e-02, -2.1057e-02,  1.0042e-02, -2.9587e-02],\n",
      "          [ 4.7787e-02, -2.8586e-02,  3.0284e-02,  3.8449e-02,  4.8077e-02],\n",
      "          [-2.3957e-03,  4.3320e-02, -1.5935e-02,  3.5782e-02, -3.4131e-02],\n",
      "          [ 4.1097e-02, -2.8680e-02, -2.1150e-02,  6.4329e-03, -4.5099e-02],\n",
      "          [ 2.0708e-02,  2.0935e-02,  8.8229e-03,  2.5444e-03,  1.8552e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2800e-02, -4.6653e-02, -4.6175e-02,  1.9908e-02,  3.5757e-02],\n",
      "          [ 3.6205e-02,  4.7203e-02,  3.3963e-02, -3.5032e-02,  9.7626e-03],\n",
      "          [-9.4451e-03, -1.7623e-02,  4.2416e-02, -2.8196e-02,  4.7392e-02],\n",
      "          [-1.9528e-02,  2.6258e-02, -2.5406e-02, -1.5116e-02,  4.4360e-02],\n",
      "          [-2.1971e-02,  3.4815e-02, -9.4041e-03, -3.7226e-04,  2.3652e-03]],\n",
      "\n",
      "         [[ 9.1965e-03,  3.8886e-02,  2.2251e-02, -8.4787e-04,  2.1048e-03],\n",
      "          [ 5.9171e-03, -1.9309e-02,  2.1198e-02, -1.7680e-02, -1.4888e-02],\n",
      "          [-3.2081e-02,  4.1048e-02,  4.6338e-02, -1.9916e-02,  3.5732e-03],\n",
      "          [ 8.8722e-03,  2.0245e-03, -1.3129e-04,  4.0893e-03,  4.9642e-02],\n",
      "          [ 4.3389e-02,  3.1694e-02, -3.7880e-02, -2.2105e-02,  2.4800e-03]],\n",
      "\n",
      "         [[ 6.4883e-03, -3.1070e-02, -3.8965e-02,  4.2837e-02,  3.8763e-02],\n",
      "          [ 2.0349e-02, -1.0229e-02, -7.3054e-04,  1.1990e-02, -2.2820e-02],\n",
      "          [ 3.1984e-02,  3.1629e-02,  1.4529e-02, -4.2122e-02,  3.4355e-02],\n",
      "          [-4.2691e-02,  1.2235e-02,  3.2700e-02,  2.5907e-02, -2.3139e-02],\n",
      "          [-1.3496e-02,  2.4426e-02, -2.0388e-02,  3.9254e-02,  5.6245e-03]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0460, -0.0034, -0.0042,  0.0251,  0.0240, -0.0223, -0.0363, -0.0324,\n",
      "         0.0481,  0.0241, -0.0455, -0.0201,  0.0409, -0.0303,  0.0100,  0.0165,\n",
      "         0.0267,  0.0087,  0.0464, -0.0324, -0.0152, -0.0062,  0.0181, -0.0491,\n",
      "        -0.0335, -0.0212, -0.0431, -0.0384,  0.0402, -0.0202, -0.0488, -0.0112],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0026, -0.0200,  0.0078,  ..., -0.0060, -0.0078,  0.0214],\n",
      "        [ 0.0160, -0.0116, -0.0024,  ...,  0.0181, -0.0065,  0.0196],\n",
      "        [-0.0049, -0.0175,  0.0015,  ...,  0.0206,  0.0030, -0.0246],\n",
      "        ...,\n",
      "        [-0.0051,  0.0179, -0.0049,  ...,  0.0134,  0.0212,  0.0070],\n",
      "        [ 0.0019, -0.0190,  0.0217,  ...,  0.0104,  0.0068, -0.0107],\n",
      "        [ 0.0026,  0.0245,  0.0064,  ...,  0.0107, -0.0153, -0.0206]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0030, -0.0052,  0.0039,  0.0110, -0.0002, -0.0167,  0.0124,  0.0173,\n",
      "         0.0194, -0.0085], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [50 x 6272], m2: [1568 x 10] at c:\\a\\w\\1\\s\\tmp_conda_3.6_062715\\conda\\conda-bld\\pytorch-cpu_1550384979956\\work\\aten\\src\\th\\generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-01204e28571f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-a55f64a6067c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-a7ce826fca10>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [50 x 6272], m2: [1568 x 10] at c:\\a\\w\\1\\s\\tmp_conda_3.6_062715\\conda\\conda-bld\\pytorch-cpu_1550384979956\\work\\aten\\src\\th\\generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model,train_loader, optimizer, epoch)\n",
    "    test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
